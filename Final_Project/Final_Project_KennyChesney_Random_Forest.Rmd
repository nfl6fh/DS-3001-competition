---
title: "Final_Project_KennyChesney_Random_Forest"
output: html_document
date: "2022-12-09"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
#install.packages("plyr")
library(plyr)
library(plotly)
#install.packages("randomForest")
library(randomForest)
library(rio)
library(caret)
library(ROCR)
library(tidyverse)
library(rpart)
#install.packages("pscyh")
library(psych)
library(pROC)
#install.packages("rpart.plot")
library(rpart.plot)
#install.packages("rattle")
library(rattle)
library(corrplot)
```



```{r}
setwd("C:/Users/Lyle_/Desktop/4 Yr Sem 1/DS 3001/DS-3001")

df <- read.csv("data/SpotifyFeatures.csv")

table(df$genre)
df2 <-unique(df)
df3 <- df2[df2$artist_name == 'Kenny Chesney',]
final_rap <- df3[-c(1, 2, 3, 4)]

```


Finish any other data prep (one-hot encode, reduce factor levels)
```{r}

factor_cols <- c(7, 10, 13)
final_rap[,factor_cols] <- lapply(final_rap[,factor_cols], as_factor)
final_rap$duration_ms <- as.numeric(final_rap$duration_ms)
final_rap$popularity <- as.numeric(final_rap$popularity)

correlationMatrix <- cor(final_rap[, sapply(final_rap, is.numeric)], use = "complete.obs", method="pearson")
corrplot(correlationMatrix, method = 'number')

```

Create test and training sets 
```{r}

sample_rows = 1:nrow(final_rap)

set.seed(1984) 
test_rows = sample(sample_rows,
                   dim(final_rap)[1]*.10,
                   replace = FALSE)


rap_train = final_rap[-test_rows,]
rap_test = final_rap[test_rows,]

```

Calculate the initial mtry level 
```{r}

dim(rap_train)

mytry_tune <- function(x){
  xx <- dim(x)[2]-1
  sqrt(xx)
}


mytry_tune(final_rap)

```

Run the initial RF model with 1000 trees 
```{r}

rap_RF = randomForest(as.numeric(popularity)~.,      
                            rap_train,
                            ntree = 1000, 
                            mtry = 4,
                            replace = TRUE,
                            sampsize = 100,
                            nodesize = 5,
                            importance = TRUE,
                            proximity = FALSE,
                            norm.votes = TRUE,
                            do.trace = TRUE,
                            keep.forest = TRUE,
                            keep.inbag = TRUE)

#==================================================================================

# Calculate the RMSE
sqrt(rap_RF$mse[length(rap_RF$mse)])
rap_RF

View(as.data.frame(rap_RF$predicted))

```

Take a look at the variable importance measures
```{r}

View(as.data.frame(varImp(rap_RF, type = 2, scale = TRUE)))

```

Use tuneRF to find optimal mtry value
```{r}
rap_RF_mtry = tuneRF(rap_train[ ,2:14],  
                           rap_train$popularity,   
                           mtryStart = 4,                        
                           ntreeTry = 100,                       
                           stepFactor = 2,                       
                           improve = 0.05,                       
                           trace = TRUE,                         
                           plot = TRUE,                          
                           doBest = FALSE)                       

rap_RF_mtry

```

Using the training data sets to tune the model in consideration of the number of trees, the number of variables to sample and the sample size that optimize the model output. 
```{r}
set.seed(1984)	
rap_RF_2 = randomForest(as.numeric(popularity)~.,
                              rap_train,
                              ntree = 1500,
                              mtry = 4,
                              replace = TRUE,
                              sampsize = 100,
                              nodesize = 5,
                              importance = TRUE,
                              proximity = FALSE,
                              norm.votes = TRUE,
                              do.trace = TRUE,
                              keep.forest = TRUE,
                              keep.inbag = TRUE) 


sqrt(rap_RF$mse[length(rap_RF$mse)])
paste("rap_RF_2 RMSE:",sqrt(rap_RF_2$mse[length(rap_RF_2$mse)]), sep=" ")
paste("rap_RF_2 NRMSE:",sqrt(rap_RF_2$mse[length(rap_RF_2$mse)])/(max(rap_train$popularity)- min(rap_train$popularity)), sep=" ")
rap_RF_2

# View(as.data.frame(rap_RF_2$predicted))

varImpPlot(rap_RF_2,
           sort = TRUE,
           n.var = 10,
           main = "Important Factors for Identifying Song Popularity",
           bg = "white",
           color = "blue",
           lcolor = "orange")



```

Once a final model has been selected (hyper-parameters of the model are set), evaluate the model using the test dataset. 
```{r}
rap_test_predict = predict(rap_RF_2,      
                            rap_test,      
                            type = "response",   
                            predict.all = TRUE)

rmse(rap_test$popularity, rap_test_predict$aggregate)
paste("rap_RF_2 test NRMSE:",rmse(rap_test$popularity, rap_test_predict$aggregate)/(max(rap_test$popularity)- min(rap_test$popularity)), sep=" ")


# rap_test_RF = randomForest(as.numeric(popularity)~.,
#                               rap_test,
#                               ntree = 1500,
#                               mtry = 4,
#                               replace = TRUE,
#                               sampsize = 10,
#                               nodesize = 5,
#                               importance = TRUE,
#                               proximity = FALSE,
#                               norm.votes = TRUE,
#                               do.trace = TRUE,
#                               keep.forest = TRUE,
#                               keep.inbag = TRUE)  
# 
# 
# rap_test_RF
# 
# sqrt(rap_test_RF$mse[length(rap_test_RF$mse)])
# 
# View(as.data.frame(rap_test_RF$predicted))
# 
# varImpPlot(rap_test_RF,
#            sort = TRUE,
#            n.var = 10,
#            main = "Important Factors for Identifying Song Popularity",
#            bg = "white",
#            color = "blue",
#            lcolor = "orange")

```